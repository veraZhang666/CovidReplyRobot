{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Covid-19 Chatbot\n",
    "\n",
    "Our purpose is to build a automatic covid-19 consulting chatbot,  we can ask questions about covid-19 including greetings, covid19 basic information, symptoms, vaccines, and travel restrictions.\n",
    "\n",
    "Our group members are :  \n",
    "    Rui Tang,100776184   \n",
    "    Juan Zhang,100777497  \n",
    "    Yali Huang,100788425\n",
    "\n",
    "Dataset(covid-19.csv, response.csv).  \n",
    "\n",
    "Approach: It's a intent based chatbot, so we build a deep learning classfication model to predict the intent, then generate the answers base on intent. We provide a Flask web application.\n",
    "\n",
    "    1. We use spacy and en_core_web_lg model do data preprocessing\n",
    "    2. We build a neural network model to train our data\n",
    "    3. Save model to intent_classfication.md\n",
    "    4. Get question from web application\n",
    "    5. Predict the intention from the intent_classfication.md model\n",
    "    6. Generate answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T13:14:15.139559Z",
     "start_time": "2021-04-15T13:14:10.389171Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\.conda\\envs\\torch11\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\admin\\.conda\\envs\\torch11\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "C:\\Users\\admin\\.conda\\envs\\torch11\\lib\\site-packages\\numpy\\.libs\\libopenblas.XWYDX2IKJW2NMTWSFYNGFUWKQU3LYTCZ.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# !python -m spacy download en_core_web_lg\n",
    "\n",
    "import spacy # 3.x version \n",
    "from spacy import displacy\n",
    "import re # regular expressions\n",
    "#import en_core_web_lg # Large SpaCy model for English language\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T14:07:05.193006Z",
     "start_time": "2021-04-14T14:07:05.189868Z"
    }
   },
   "source": [
    "## Load Questions and Responses Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T13:14:15.169932Z",
     "start_time": "2021-04-15T13:14:15.141350Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>questions</th>\n",
       "      <th>intent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hello</td>\n",
       "      <td>greetings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hi</td>\n",
       "      <td>greetings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey</td>\n",
       "      <td>greetings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hello, how are you?</td>\n",
       "      <td>greetings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I need help</td>\n",
       "      <td>greetings</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             questions     intent\n",
       "0                Hello  greetings\n",
       "1                  Hi   greetings\n",
       "2                  Hey  greetings\n",
       "3  hello, how are you?  greetings\n",
       "4          I need help  greetings"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load question and intent dataset\n",
    "data_df = pd.read_csv('covid_19.csv',names=[\"questions\",\"intent\"])\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T13:14:15.185890Z",
     "start_time": "2021-04-15T13:14:15.171888Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intent</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>greetings</td>\n",
       "      <td>Hi, I'm robot XiaoMing, how can I help you?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>information</td>\n",
       "      <td>Coronavirus disease (COVID-19) is an infectiou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>symptoms</td>\n",
       "      <td>COVID-19 affects different people in different...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>prevention</td>\n",
       "      <td>Clean your hands often. Use soap and water, or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vaccine</td>\n",
       "      <td>Residents who are eligible can book an appoint...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        intent                                           response\n",
       "0    greetings        Hi, I'm robot XiaoMing, how can I help you?\n",
       "1  information  Coronavirus disease (COVID-19) is an infectiou...\n",
       "2     symptoms  COVID-19 affects different people in different...\n",
       "3   prevention  Clean your hands often. Use soap and water, or...\n",
       "4      vaccine  Residents who are eligible can book an appoint..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load response dataset\n",
    "response_df = pd.read_csv('response.csv',names=[\"intent\",\"response\"])\n",
    "response_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T13:14:15.201891Z",
     "start_time": "2021-04-15T13:14:15.187890Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'greetings': [\"Hi, I'm robot XiaoMing, how can I help you?\"], 'information': ['Coronavirus disease (COVID-19) is an infectious disease caused by a newly discovered coronavirus.Most people infected with the COVID-19 virus will experience mild to moderate respiratory illness and recover without requiring special treatment.  Older people, and those with underlying medical problems like cardiovascular disease, diabetes, chronic respiratory disease, and cancer are more likely to develop serious illness.'], 'symptoms': ['COVID-19 affects different people in different ways. Most infected people will develop mild to moderate illness and recover without hospitalization. Most common symptoms: fever, dry cough,tiredness. Less common symtoms: aches and pains, sore throat,diarrhoea,conjunctivitis,headache, loss of taste or smell,a rash on skin, or discolouration of fingers or toes.'], 'prevention': [\"Clean your hands often. Use soap and water, or an alcohol-based hand rub.Maintain a safe distance from anyone who is coughing or sneezing.Wear a mask when physical distancing is not possible.Don't touch your eyes, nose or mouth.Cover your nose and mouth with your bent elbow or a tissue when you cough or sneeze.Stay home if you feel unwell.If you have a fever, cough and difficulty breathing, seek medical attention.\"], 'vaccine': ['Residents who are eligible can book an appointment at immunization clinics in Toronto using the Province vaccination registration system (note browser requirements) or by calling the Provincial Vaccine Information Line at 1-888-999-6488'], 'travel': ['Mandatory qurantine is required when enter Canada, see more detail at https://www.canada.ca/en/immigration-refugees-citizenship/corporate/publications-manuals/operational-bulletins-manuals/service-delivery/coronavirus/travel-restrictions.html'], 'default': [\"Sorry, I don't understand your question,  could you try other ways ?\"]}\n"
     ]
    }
   ],
   "source": [
    "#convert response and intent pair to dictionary\n",
    "responses_dict = response_df.set_index('intent').T.to_dict('list')\n",
    "print(responses_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataPreprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T13:14:17.256677Z",
     "start_time": "2021-04-15T13:14:15.203891Z"
    }
   },
   "outputs": [],
   "source": [
    "#load the pretrained spacy model\n",
    "# $: python -m spacy download en_core_web_lg\n",
    "# Including Vocabulary, syntax, entities, vectors\n",
    "# word vector size: 685k keys, 685k unique vectors (300 dimensions)\n",
    "# From : written text (blogs, news, comments)\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "#nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T13:14:17.272395Z",
     "start_time": "2021-04-15T13:14:17.258975Z"
    }
   },
   "outputs": [],
   "source": [
    "# nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T13:14:17.288401Z",
     "start_time": "2021-04-15T13:14:17.274399Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I did my homework at 2 pm in the afternoon \n",
      "I PRON nsubj\n",
      "did VERB ROOT\n",
      "my PRON poss\n",
      "homework NOUN dobj\n",
      "at ADP prep\n",
      "2 NUM nummod\n",
      "pm NOUN pobj\n",
      "in ADP prep\n",
      "the DET det\n",
      "afternoon NOUN pobj\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['I', 'did', 'my', 'homework', 'at', '2', 'pm', 'in', 'the', 'afternoon']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ['word','word'] <---text \n",
    "def get_all_tokens(text):\n",
    "    doc = nlp(text)\n",
    "    d = defaultdict(list)\n",
    "    print(doc)    \n",
    "    tokens = []\n",
    "    for token in doc:\n",
    "        print(token.text, token.pos_, token.dep_) #(str,str,str)            \n",
    "        tokens.append(token.text)\n",
    "    return tokens\n",
    "get_all_tokens('I did my homework at 2 pm in the afternoon ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T13:14:17.320399Z",
     "start_time": "2021-04-15T13:14:17.291399Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'list'>, {'GPE': ['Beijing'], 'PERSON': ['LiLi'], 'TIME': ['3:00 pm'], 'DATE': ['May 1st of 2021']})\n"
     ]
    }
   ],
   "source": [
    "def get_all_entities(text):\n",
    "    \"\"\"\n",
    "        Get all entities in a given text, in a text: label_ dictionary\n",
    "    \"\"\"\n",
    "    doc = nlp(text)\n",
    "    #print(doc)\n",
    "    \n",
    "    d = defaultdict(list)\n",
    "    for ent in doc.ents:\n",
    "        d[ent.label_].append(ent.text)\n",
    "    print(d)\n",
    "    return(d)\n",
    "text = 'I want to travel to Beijing with LiLi at 3:00 pm in May 1st of 2021'\n",
    "test_ents  = get_all_entities(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T13:14:17.350397Z",
     "start_time": "2021-04-15T13:14:17.322399Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">I want to travel to \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Beijing\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " with \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    LiLi\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " at \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    3:00 pm\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">TIME</span>\n",
       "</mark>\n",
       " in \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    May 1st of 2021\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       "</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#visualize the entities\n",
    "doc = nlp(text)\n",
    "displacy.render(doc, style='ent', jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T13:14:17.366392Z",
     "start_time": "2021-04-15T13:14:17.353400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3:00 pm in May 1st of 2021'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate data and time entities, we can put them in the answer\n",
    "def CheckDataTimeEnts(entities):\n",
    "    time = \"\"\n",
    "    if 'TIME' in entities and 'DATE' in entities:\n",
    "        time =  ' '.join(entities['TIME']) +' in '+ ' '.join(entities['DATE'])\n",
    "    elif 'TIME' in entities:\n",
    "        time = ' and '.join(entities['TIME'])\n",
    "    elif 'DATE' in entities:\n",
    "        time = ' and '.join(entities['DATE'])\n",
    "    else:\n",
    "        time = \"\"\n",
    "    return time\n",
    "CheckDataTimeEnts(test_ents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T13:14:17.398450Z",
     "start_time": "2021-04-15T13:14:17.368392Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7886899459766993\n",
      "0.5354245353815981\n"
     ]
    }
   ],
   "source": [
    "#calculate the similarity\n",
    "doc1 = nlp(u\"what is the symtom of crona virus\")\n",
    "doc2 = nlp(u\"contracted the crona virus\")\n",
    "doc3 = nlp(u'is fever one of the symtom of HPV?')\n",
    "similarity = doc1.similarity(doc2)\n",
    "s2 = doc2.similarity(doc3)\n",
    "print(similarity)\n",
    "print(s2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the trainning dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T13:14:17.414549Z",
     "start_time": "2021-04-15T13:14:17.401399Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>questions</th>\n",
       "      <th>intent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hello</td>\n",
       "      <td>greetings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hi</td>\n",
       "      <td>greetings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey</td>\n",
       "      <td>greetings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hello, how are you?</td>\n",
       "      <td>greetings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I need help</td>\n",
       "      <td>greetings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Fly to Canada</td>\n",
       "      <td>travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Fight</td>\n",
       "      <td>travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>What are the travel restrictions</td>\n",
       "      <td>travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Restriction</td>\n",
       "      <td>travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>qurantine</td>\n",
       "      <td>travel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>77 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           questions     intent\n",
       "0                              Hello  greetings\n",
       "1                                Hi   greetings\n",
       "2                                Hey  greetings\n",
       "3                hello, how are you?  greetings\n",
       "4                        I need help  greetings\n",
       "..                               ...        ...\n",
       "72                     Fly to Canada     travel\n",
       "73                             Fight     travel\n",
       "74  What are the travel restrictions     travel\n",
       "75                       Restriction     travel\n",
       "76                         qurantine     travel\n",
       "\n",
       "[77 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#set the train and label data\n",
    "trainining_sentences =data_df.questions\n",
    "\n",
    "#conver the intent to one hot code\n",
    "training_intents =  pd.get_dummies(data_df.intent)\n",
    "\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T13:14:17.979586Z",
     "start_time": "2021-04-15T13:14:17.416551Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data shape :  (77, 300)\n"
     ]
    }
   ],
   "source": [
    "# Creating the word embedding vectors shape:(sentence_len,300)\n",
    "# 1 sentence map to 300 dimention vector. \n",
    "def getWordVectors(trainining_sentences):\n",
    "        embed_vec_dim = nlp('').vocab.vectors_length # 300 dim \n",
    "        X_train = np.zeros((len(trainining_sentences), embed_vec_dim))\n",
    "        \n",
    "        print('training data shape : ',X_train.shape)\n",
    "        \n",
    "        for i, sentence in enumerate(trainining_sentences):\n",
    "            #lower the sentence\n",
    "            sentence = sentence.lower()\n",
    "            # Pass each each sentence to the nlp object to create a document\n",
    "            doc = nlp(sentence)\n",
    "            # Save the document's .vector attribute to the corresponding row in X\n",
    "            X_train[i, :] = doc.vector\n",
    "        return X_train \n",
    "\n",
    "\n",
    "X_train = getWordVectors(trainining_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model to train the question-intent dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T13:14:17.995587Z",
     "start_time": "2021-04-15T13:14:17.981397Z"
    }
   },
   "outputs": [],
   "source": [
    "#build model structure\n",
    "def build_network_model(n_layers = 4, n_nodes = 16):\n",
    "    \n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.Input(shape=(300,)))\n",
    "    \n",
    "    for i in range(n_layers):\n",
    "        model.add(Dense(n_nodes, activation=\"relu\"))\n",
    "        \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    #total 6 classes\n",
    "    model.add(Dense(training_intents.shape[1],activation='softmax'))\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T13:14:19.225514Z",
     "start_time": "2021-04-15T13:14:17.997428Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 16)                4816      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 6)                 102       \n",
      "=================================================================\n",
      "Total params: 5,734\n",
      "Trainable params: 5,734\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_network_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T13:14:22.527303Z",
     "start_time": "2021-04-15T13:14:19.227407Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(77, 6)\n",
      "Epoch 1/80\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": " Blas GEMM launch failed : a.shape=(32, 300), b.shape=(300, 16), m=32, n=16, k=300\n\t [[node sequential/dense/MatMul (defined at \\AppData\\Local\\Temp/ipykernel_6864/4173055640.py:21) ]] [Op:__inference_train_function_827]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6864/4173055640.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m80\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mearly_stop\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\.conda\\envs\\torch11\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1098\u001b[0m                 _r=1):\n\u001b[0;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1101\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\torch11\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\torch11\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    886\u001b[0m         \u001b[1;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m         \u001b[1;31m# stateless function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 888\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    889\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    890\u001b[0m       \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\torch11\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m-> 2943\u001b[1;33m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m   2944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2945\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\torch11\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1917\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1919\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\torch11\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 560\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    561\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\.conda\\envs\\torch11\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInternalError\u001b[0m:  Blas GEMM launch failed : a.shape=(32, 300), b.shape=(300, 16), m=32, n=16, k=300\n\t [[node sequential/dense/MatMul (defined at \\AppData\\Local\\Temp/ipykernel_6864/4173055640.py:21) ]] [Op:__inference_train_function_827]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "#set early stop when no imporvement for 5 times\n",
    "# gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.333)  \n",
    "# sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))  \n",
    "# import tensorflow as tf\n",
    "# tf.compat.v1.GPUOptions(per_process_gpu_memory_fraction)\n",
    "# from keras.backend.tensorflow_backend import set_session\n",
    "# config = tf.ConfigProto()\n",
    "# config.gpu_options.allocator_type = 'BFC' #A \"Best-fit with coalescing\" algorithm, simplified from a version of dlmalloc.\n",
    "# config.gpu_options.per_process_gpu_memory_fraction = 0.3\n",
    "# config.gpu_options.allow_growth = True\n",
    "# set_session(tf.Session(config=config)) \n",
    "\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5)\n",
    "\n",
    "#train the model\n",
    "Y_train = training_intents\n",
    "print(Y_train.shape) # 77*4 \n",
    "\n",
    "\n",
    "history = model.fit(X_train, Y_train, epochs=80, verbose=1,callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T13:14:23.040693Z",
     "start_time": "2021-04-15T13:14:22.529297Z"
    }
   },
   "outputs": [],
   "source": [
    "#visualize the training result\n",
    "import matplotlib.pyplot as pyplot\n",
    "pyplot.plot(history.history['accuracy'], label='training_accuracy')\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.ylabel('accuracy')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T13:14:24.252408Z",
     "start_time": "2021-04-15T13:14:23.042695Z"
    }
   },
   "outputs": [],
   "source": [
    "#save the model\n",
    "model.save('intent_classfication_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T13:14:24.853589Z",
     "start_time": "2021-04-15T13:14:24.254407Z"
    }
   },
   "outputs": [],
   "source": [
    "#load the model\n",
    "model = tf.keras.models.load_model('intent_classfication_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T14:20:46.189722Z",
     "start_time": "2021-04-14T14:20:46.175693Z"
    }
   },
   "source": [
    "## Predict intent using the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T13:14:24.869568Z",
     "start_time": "2021-04-15T13:14:24.855535Z"
    }
   },
   "outputs": [],
   "source": [
    "#predict intent\n",
    "labels = ['greetings','information','prevention','symptoms','travel','vaccine']\n",
    "def predict_intent(text):\n",
    "    #lower the text\n",
    "    text = text.lower()\n",
    "    \n",
    "    #convert to 300size sentence\n",
    "    doc = nlp(text)\n",
    "    x = doc.vector\n",
    "    \n",
    "    #add one dimination to input shape\n",
    "    x1 = x[np.newaxis, :]\n",
    "    \n",
    "    #predict\n",
    "    label = np.argmax(model.predict(x1), axis=-1)\n",
    "    \n",
    "    return labels[label[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T13:14:24.885538Z",
     "start_time": "2021-04-15T13:14:24.871534Z"
    }
   },
   "outputs": [],
   "source": [
    "#generate answers\n",
    "def respond_ml(text):\n",
    "    \n",
    "    intent = predict_intent(text)\n",
    "    print(intent)\n",
    "    \n",
    "    response = responses_dict.get(intent)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test by questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T13:18:03.521138Z",
     "start_time": "2021-04-15T13:17:00.137240Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Please input your questions or enter 'quit' to exit.\")\n",
    "while True:\n",
    "    quesion = input('Patient: ')\n",
    "    if quesion.lower() == 'quit':\n",
    "        break\n",
    "    response = respond_ml(quesion)\n",
    "    print(f'Robot: {response}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T14:12:51.349540Z",
     "start_time": "2021-04-14T14:12:51.340501Z"
    }
   },
   "source": [
    "## Build the chatbot webapplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T13:20:03.069315Z",
     "start_time": "2021-04-15T13:18:16.848208Z"
    }
   },
   "outputs": [],
   "source": [
    "from flask import Flask, render_template, request, jsonify\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route(\"/\")\n",
    "def hello():\n",
    "    return render_template('chat.html')\n",
    "\n",
    "@app.route(\"/ask\", methods=['POST'])\n",
    "def ask():\n",
    "    message = request.form['messageText']\n",
    "    print(message)\n",
    "    while True:\n",
    "        if message == \"quit\":\n",
    "            exit()\n",
    "        else:\n",
    "            bot_response = respond_ml(message)\n",
    "            print(bot_response)\n",
    "            return jsonify({'status':'OK','answer':bot_response})\n",
    "app.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generate requirement.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T13:20:12.785963Z",
     "start_time": "2021-04-15T13:20:11.375096Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip freeze >requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch11",
   "language": "python",
   "name": "torch11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
